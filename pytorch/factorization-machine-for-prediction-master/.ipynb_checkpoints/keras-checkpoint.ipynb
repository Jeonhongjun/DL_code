{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created by qqgeogor\n",
    "#### https://www.kaggle.com/qqgeogor\n",
    "#### https://www.kaggle.com/qqgeogor/keras-based-fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from keras.layers import Input, Embedding, Dense,Flatten, merge,Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2 as l2_reg\n",
    "from keras import initializers\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(size, batch_size):\n",
    "    nb_batch = int(np.ceil(size/float(batch_size)))\n",
    "    return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n",
    "\n",
    "\n",
    "def batch_generator(X,y,batch_size=128,shuffle=True):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(index_array)\n",
    "        batches = make_batches(sample_size, batch_size)\n",
    "        for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "            batch_ids = index_array[batch_start:batch_end]\n",
    "            X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "            y_batch = y[batch_ids]\n",
    "            yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def test_batch_generator(X,y,batch_size=128):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    batches = make_batches(sample_size, batch_size)\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "        batch_ids = index_array[batch_start:batch_end]\n",
    "        X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "        y_batch = y[batch_ids]\n",
    "        yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def predict_batch(model,X_t,batch_size=128):\n",
    "    outcome = []\n",
    "    for X_batch,y_batch in test_batch_generator(X_t,np.zeros(X_t[0].shape[0]),batch_size=batch_size):\n",
    "        outcome.append(model.predict(X_batch,batch_size=batch_size))\n",
    "    outcome = np.concatenate(outcome).ravel()\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_features,K=8,solver='adam',l2=0.0,l2_fm = 0.0):\n",
    "\n",
    "    inputs = []\n",
    "    flatten_layers=[]\n",
    "    columns = range(len(max_features))\n",
    "    for c in columns:\n",
    "        inputs_c = Input(shape=(1,), dtype='int32',name = 'input_%s'%c)\n",
    "        num_c = max_features[c]\n",
    "\n",
    "        embed_c = Embedding(\n",
    "                        num_c,\n",
    "                        K,\n",
    "                        input_length=1,\n",
    "                        name = 'embed_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2_fm)\n",
    "                        )(inputs_c)\n",
    "\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        inputs.append(inputs_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "\n",
    "    fm_layers = []\n",
    "    for emb1,emb2 in itertools.combinations(flatten_layers, 2):\n",
    "        dot_layer = merge([emb1,emb2],mode='dot',dot_axes=1)\n",
    "        fm_layers.append(dot_layer)\n",
    "\n",
    "    for c in columns:\n",
    "        num_c = max_features[c]\n",
    "        embed_c = Embedding(\n",
    "                        num_c,\n",
    "                        1,\n",
    "                        input_length=1,\n",
    "                        name = 'linear_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2)\n",
    "                        )(inputs[c])\n",
    "\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        fm_layers.append(flatten_c)\n",
    "        \n",
    "        \n",
    "    flatten = merge(fm_layers,mode='sum')\n",
    "    outputs = Activation('sigmoid',name='outputs')(flatten)\n",
    "    \n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=solver,\n",
    "                loss= 'binary_crossentropy'\n",
    "              )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasFM(BaseEstimator):\n",
    "    def __init__(self,max_features=[],K=8,solver='adam',l2=0.0,l2_fm = 0.0):\n",
    "        self.model = build_model(max_features,K,solver,l2=l2,l2_fm = l2_fm)\n",
    "\n",
    "    def fit(self,X,y,batch_size=128,nb_epoch=10,shuffle=True,verbose=1,validation_data=None):\n",
    "        self.model.fit(X,y,batch_size=batch_size,nb_epoch=nb_epoch,shuffle=shuffle,verbose=verbose,validation_data=None)\n",
    "\n",
    "    def fit_generator(self,X,y,batch_size=128,nb_epoch=10,shuffle=True,verbose=1,validation_data=None,callbacks=None):\n",
    "        tr_gen = batch_generator(X,y,batch_size=batch_size,shuffle=shuffle)\n",
    "        if validation_data:\n",
    "            X_test,y_test = validation_data\n",
    "            te_gen = batch_generator(X_test,y_test,batch_size=batch_size,shuffle=False)\n",
    "            nb_val_samples = X_test[-1].shape[0]\n",
    "        else:\n",
    "            te_gen = None\n",
    "            nb_val_samples = None\n",
    "\n",
    "        self.model.fit_generator(\n",
    "                tr_gen, \n",
    "                samples_per_epoch=X[-1].shape[0], \n",
    "                nb_epoch=nb_epoch, \n",
    "                verbose=verbose, \n",
    "                callbacks=callbacks, \n",
    "                validation_data=te_gen, \n",
    "                nb_val_samples=nb_val_samples, \n",
    "                max_q_size=10\n",
    "                )\n",
    "\n",
    "    def predict(self,X,batch_size=128):\n",
    "        y_preds = predict_batch(self.model,X,batch_size=batch_size)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
